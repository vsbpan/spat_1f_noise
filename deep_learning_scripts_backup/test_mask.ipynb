{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee586206-75a5-4560-b695-bd9780f3f9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Installation info\n",
    "# conda create -n detectron_env python=3.8\n",
    "# conda activate detectron_env\n",
    "# conda install cython\n",
    "# conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia\n",
    "# git clone https://github.com/facebookresearch/detectron2.git\n",
    "# cd detectron2\n",
    "# conda install -e .\n",
    "# conda install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a4a659-99fa-4ae5-a0be-31f206071eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Virtual environment and notebook init\n",
    "# Call conda activate detectron_env\n",
    "# cd C:\\R_projects\\deep_learning_playground\n",
    "# Call jupyter lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7220c27-d638-46b8-a07a-e31ff594af2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check working directory\n",
    "# pwd\n",
    "### Check if entered correct environment\n",
    "# conda info --envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614d3637-2f19-410a-ad9e-d760b70e4d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, detectron2\n",
    "!nvcc --version\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "print(\"detectron2:\", detectron2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78437cf5-f4e6-4e4a-905b-b793424ad3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor,DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.utils.visualizer import ColorMode,GenericMask,Visualizer\n",
    "from detectron2.structures.keypoints import heatmaps_to_keypoints\n",
    "from detectron2.structures.keypoints_hack import heatmaps_to_keypoints2, heatmaps_to_keypoints_iterative, heatmaps_modify_iterative\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "import random\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.evaluation import (\n",
    "    CityscapesInstanceEvaluator,\n",
    "    CityscapesSemSegEvaluator,\n",
    "    COCOEvaluator,\n",
    "    COCOPanopticEvaluator,\n",
    "    LVISEvaluator,\n",
    "    PascalVOCDetectionEvaluator,\n",
    "    SemSegEvaluator,\n",
    "    DatasetEvaluator,\n",
    "    inference_on_dataset,\n",
    "    print_csv_format,\n",
    "    verify_results,\n",
    ")\n",
    "import cv2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4082c49a-e8eb-47c3-ad1b-e269ceee9ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2.imshow(\"my_image\", cv2.imread(r\"C:\\R_projects\\deep_learning_playground\\detectron2\\demo\\cat.jpg\"))\n",
    "#cv2.waitKey(0) \n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea952b8d-9d32-4c39-91e9-ffcfe226dd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd C:\\R_projects\\deep_learning_playground\\detectron2\\custom_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e90549-fc6e-4899-9030-c862cf67f80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and test data\n",
    "# !coco-split --has_annotations --valid_ratio 0 --test_ratio 0.1 --annotations_file ./coco_annotations.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b908c2ab-2c50-4621-84fa-205c29562d83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "register_coco_instances(\"cat_data_train\", {}, \".\\coco_train.json\", \".\\datasets\\caterpillar\")\n",
    "register_coco_instances(\"cat_data_test\", {}, \".\\coco_test.json\", \".\\datasets\\caterpillar\")\n",
    "#register_coco_instances(\"cat_data_val\", {}, \".\\valid.json\", \".\\datasets\\caterpillar\")\n",
    "MetadataCatalog.get(\"cat_data_train\").set(thing_classes=[\"cat\"])\n",
    "MetadataCatalog.get(\"cat_data_train\").set(thing_colors=(0,0,255))\n",
    "MetadataCatalog.get(\"cat_data_test\").set(thing_classes=[\"cat\"])\n",
    "MetadataCatalog.get(\"cat_data_test\").set(thing_colors=(0,0,255))\n",
    "MetadataCatalog.get(\"cat_data_train\").set(keypoint_names=[\"head\",\"middle\",\"tail\"])\n",
    "MetadataCatalog.get(\"cat_data_train\").set(keypoint_flip_map=[])\n",
    "MetadataCatalog.get(\"cat_data_test\").set(keypoint_names=[\"head\",\"middle\",\"tail\"])\n",
    "MetadataCatalog.get(\"cat_data_test\").set(keypoint_flip_map=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39ae945-4c3e-4101-902b-608064303c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine.hooks import HookBase\n",
    "from detectron2.evaluation import inference_context\n",
    "from detectron2.utils.logger import log_every_n_seconds\n",
    "from detectron2.data import DatasetMapper, build_detection_test_loader\n",
    "import detectron2.utils.comm as comm\n",
    "import torch\n",
    "import time\n",
    "import datetime\n",
    "import logging\n",
    "\n",
    "class LossEvalHook(HookBase):\n",
    "    def __init__(self, eval_period, model, data_loader):\n",
    "        self._model = model\n",
    "        self._period = eval_period\n",
    "        self._data_loader = data_loader\n",
    "    \n",
    "    def _do_loss_eval(self):\n",
    "        # Copying inference_on_dataset from evaluator.py\n",
    "        total = len(self._data_loader)\n",
    "        num_warmup = min(5, total - 1)\n",
    "            \n",
    "        start_time = time.perf_counter()\n",
    "        total_compute_time = 0\n",
    "        losses = []\n",
    "        for idx, inputs in enumerate(self._data_loader):            \n",
    "            if idx == num_warmup:\n",
    "                start_time = time.perf_counter()\n",
    "                total_compute_time = 0\n",
    "            start_compute_time = time.perf_counter()\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.synchronize()\n",
    "            total_compute_time += time.perf_counter() - start_compute_time\n",
    "            iters_after_start = idx + 1 - num_warmup * int(idx >= num_warmup)\n",
    "            seconds_per_img = total_compute_time / iters_after_start\n",
    "            if idx >= num_warmup * 2 or seconds_per_img > 5:\n",
    "                total_seconds_per_img = (time.perf_counter() - start_time) / iters_after_start\n",
    "                eta = datetime.timedelta(seconds=int(total_seconds_per_img * (total - idx - 1)))\n",
    "                log_every_n_seconds(\n",
    "                    logging.INFO,\n",
    "                    \"Loss on Validation  done {}/{}. {:.4f} s / img. ETA={}\".format(\n",
    "                        idx + 1, total, seconds_per_img, str(eta)\n",
    "                    ),\n",
    "                    n=5,\n",
    "                )\n",
    "            loss_batch = self._get_loss(inputs)\n",
    "            losses.append(loss_batch)\n",
    "        mean_loss = np.mean(losses)\n",
    "        self.trainer.storage.put_scalar('validation_loss', mean_loss)\n",
    "        comm.synchronize()\n",
    "\n",
    "        return losses\n",
    "            \n",
    "    def _get_loss(self, data):\n",
    "        # How loss is calculated on train_loop \n",
    "        metrics_dict = self._model(data)\n",
    "        metrics_dict = {\n",
    "            k: v.detach().cpu().item() if isinstance(v, torch.Tensor) else float(v)\n",
    "            for k, v in metrics_dict.items()\n",
    "        }\n",
    "        total_losses_reduced = sum(loss for loss in metrics_dict.values())\n",
    "        return total_losses_reduced\n",
    "        \n",
    "        \n",
    "    def after_step(self):\n",
    "        next_iter = self.trainer.iter + 1\n",
    "        is_final = next_iter == self.trainer.max_iter\n",
    "        if is_final or (self._period > 0 and next_iter % self._period == 0):\n",
    "            self._do_loss_eval()\n",
    "        self.trainer.storage.put_scalars(timetest=12)\n",
    "\n",
    "from detectron2.data import DatasetMapper, build_detection_test_loader\n",
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "class CustomTrainer(DefaultTrainer):\n",
    "    \"\"\"\n",
    "    Custom Trainer deriving from the \"DefaultTrainer\"\n",
    "\n",
    "    Overloads build_hooks to add a hook to calculate loss on the test set during training.\n",
    "    \"\"\"\n",
    "\n",
    "    def build_hooks(self):\n",
    "        hooks = super().build_hooks()\n",
    "        hooks.insert(-1, LossEvalHook(\n",
    "            200, # Frequency of calculation - every 100 iterations here\n",
    "            self.model,\n",
    "            build_detection_test_loader(\n",
    "                self.cfg,\n",
    "                self.cfg.DATASETS.TEST[0],\n",
    "                DatasetMapper(self.cfg, True)\n",
    "            )\n",
    "        ))\n",
    "\n",
    "        return hooks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6a2f5b-0a9e-4407-94d5-d92bc6dd5519",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from detectron2.config import LazyConfig, instantiate\n",
    "\n",
    "# cfg = model_zoo.get_config(\"new_baselines/mask_rcnn_R_50_FPN_400ep_LSJ.py\", trained=True)\n",
    "# cfg.train.init_checkpoint = instantiate(cfg.model)\n",
    "# cfg.dataloader.train.dataset.names = (\"my_dataset_train\",)\n",
    "# cfg.dataloader.test.dataset.names = (\"newdata_test\", )\n",
    "# cfg.train.max_iter = 3000\n",
    "# cfg.train.output_dir = \"./output2\"\n",
    "# cfg.train.log_period = 200\n",
    "# cfg.train.eval_period = 200\n",
    "# cfg.train.checkpointer.period = 2000\n",
    "# cfg.train.checkpointer.max_to_keep=100\n",
    "# cfg.model.proposal_generator.batch_size_per_image = 256\n",
    "# cfg.model.roi_heads.num_classes = 1\n",
    "# cfg.model.roi_heads.batch_size_per_image = 128\n",
    "# cfg.model.roi_heads.test_score_thresh = 0.9\n",
    "# cfg.optimizer.lr = 0.00015\n",
    "# cfg.optimizer.weight_decay = 0\n",
    "# os.makedirs(cfg.train.output_dir, exist_ok=True)\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"cat_data_train\",)\n",
    "cfg.DATASETS.TEST = (\"cat_data_test\", )\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.TEST.EVAL_PERIOD = 200\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2  # This is the real \"batch size\" commonly known to deep learning people\n",
    "cfg.SOLVER.BASE_LR = 0.00015  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 3000    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
    "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # The \"RoIHead batch size\". 128 is faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1 \n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.9\n",
    "cfg.TEST.DETECTIONS_PER_IMAGE = 1\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = 2000\n",
    "cfg.MODEL.ROI_KEYPOINT_HEAD.NUM_KEYPOINTS = 3\n",
    "cfg.TEST.KEYPOINT_OKS_SIGMAS = [0.1, 0.3, 0.1]\n",
    "cfg.INPUT.RANDOM_FLIP = \"horizontal\"\n",
    "cfg.MODEL.MASK_ON = True\n",
    "cfg.MODEL.KEYPOINT_ON = True\n",
    "cfg.MODEL.ROI_KEYPOINT_HEAD.LOSS_WEIGHT = 5\n",
    "cfg.MODEL.ROI_KEYPOINT_HEAD.NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS = False\n",
    "#cfg.MODEL.ROI_KEYPOINT_HEAD.ITERATIVE = True\n",
    "cfg.INPUT.USE_DIFF = False                      # Include difference in green channel 10 frames ago as the 4th channel\n",
    "cfg.OUTPUT_DIR = \"./output5\"\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f673cb61-0018-4eec-990c-df88a31e3d53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecbdc5b-59a6-4906-bd61-45cd0e9d6f61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#trainer = DefaultTrainer(cfg)\n",
    "trainer = CustomTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845ee350-0d0a-4bf5-975d-39aed5e9bece",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "#%reload_ext tensorboard\n",
    "%tensorboard --logdir \"./output5\"\n",
    "# !del /S C:\\Users\\vsbpa\\AppData\\Local\\Temp\\.tensorboard-info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29502328-f162-4531-b70d-f246bad5e7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference should use the config with parameters that are used in training\n",
    "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_0001999.pth\")  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.9  # set a custom testing threshold\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8020887a-df4d-4687-9bf8-b6e6319a94b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "# f = glob.glob(\"C:\\R_projects\\deep_learning_playground\\detectron2\\custom_data\\coco_dataset\\*.jpg\")\n",
    "f = glob.glob(\"C:/R_projects/spat_1f_noise/processed_feed/rep50/*.jpg\")\n",
    "# f = [\"C:/R_projects/spat_1f_noise/processed_feed/repweek2test2/processed_repweek2test2__cam28_s36764_rank103.jpg\"]\n",
    "fi = random.choice(f)\n",
    "#fi = f[0]\n",
    "im = cv2.imread(fi)\n",
    "outputs = predictor(im)  # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
    "v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata=MetadataCatalog.get(\"cat_data_train\"), \n",
    "                   scale=1, \n",
    "               instance_mode=ColorMode.IMAGE_BW\n",
    ")\n",
    "\n",
    "#out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "\n",
    "try: out = v.draw_circle((outputs[\"instances\"].pred_keypoints.tolist())[0][0][:2:], \"red\", radius = 5)\n",
    "except: \n",
    "    print(\"Head not detected\") \n",
    "    out =  v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "try: out = v.draw_circle((outputs[\"instances\"].pred_keypoints.tolist())[0][1][:2:], \"black\")\n",
    "except: print(\"Middle not detected\") \n",
    "try: out = v.draw_circle((outputs[\"instances\"].pred_keypoints.tolist())[0][2][:2:], \"green\")\n",
    "except: print(\"Tail not detected\") \n",
    "try: out = v.draw_soft_mask(np.asarray(outputs[\"instances\"].to(\"cpu\").pred_masks)[0,:,:], \"blue\",alpha = 0.3)\n",
    "except: print(\"Mask not detected\") \n",
    "\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.imshow(out.get_image(), interpolation='nearest')\n",
    "plt.title(fi)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136a40da-03cb-4300-bc63-9473f25f0d55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae920ee-811a-495a-bda8-f20b41ffa9ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e2b72e-66f6-405f-bb37-62354579ac52",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = glob.glob(\"C:/R_projects/deep_learning_playground/test_data/rep15/*[!_diff].jpg\")\n",
    "tot = len(f)\n",
    "for i in range(tot):\n",
    "    fi = f[i]\n",
    "    im = cv2.imread(fi)\n",
    "    outputs = predictor(im) \n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata=MetadataCatalog.get(\"cat_data_train\"), \n",
    "                   scale=0.5, \n",
    "                   instance_mode=ColorMode.IMAGE_BW\n",
    "    )\n",
    "    #out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    try: out = v.draw_box(outputs[\"instances\"].pred_boxes.tensor.tolist()[0])\n",
    "    except: out = v.draw_circle((0,0), radius = 0, color = \"black\")\n",
    "    try: out = v.draw_circle((outputs[\"instances\"].pred_keypoints.tolist())[0][0][:2:], color = \"red\", radius = 3)\n",
    "    except: 1\n",
    "    try: out = v.draw_circle((outputs[\"instances\"].pred_keypoints.tolist())[0][1][:2:], color = \"black\", radius = 2)\n",
    "    except: 1\n",
    "    try: out = v.draw_circle((outputs[\"instances\"].pred_keypoints.tolist())[0][2][:2:], color = \"green\", radius = 2)\n",
    "    except: 1\n",
    "    try: out = v.draw_soft_mask(np.asarray(outputs[\"instances\"].to(\"cpu\").pred_masks)[0,:,:], \"blue\",alpha = 0.3)\n",
    "    except: 1\n",
    "    fp = os.path.join(\"C:/R_projects/deep_learning_playground/detectron2/custom_data2/model5_vid_pred_15\", os.path.basename(fi))\n",
    "    cv2.imwrite(fp, cv2.cvtColor(out.get_image(), cv2.COLOR_BGR2RGB))\n",
    "    print(f\"{i+1} of {tot}\", end = \"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492413ca-d9c3-4014-9d5a-2653b7e450bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_0001999.pth\")  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.9  # set a custom testing threshold\n",
    "predictor = DefaultPredictor(cfg)\n",
    "evaluator = COCOEvaluator(\"cat_data_test\",tasks=[\"bbox\",\"segm\",\"keypoints\"], distributed=False, max_dets_per_image=1, \n",
    "                          use_fast_impl=False, allow_cached_coco= False, output_dir=\"./output/\", kpt_oks_sigmas = [0.1,0.5,0.1])\n",
    "val_loader = build_detection_test_loader(cfg, \"cat_data_test\")\n",
    "detectron2.evaluation.inference_on_dataset(predictor.model, val_loader, evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9e8659-e64b-4738-a473-b495a71ce1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuts_metadata = MetadataCatalog.get('cat_data_test')\n",
    "dataset_dicts = DatasetCatalog.get(\"cat_data_test\")\n",
    "fig = plt.figure(figsize=(15,30)) \n",
    "\n",
    "i = 0\n",
    "for d in dataset_dicts:\n",
    "    i += 1\n",
    "    fig.add_subplot(11, 4, i) \n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    outputs = predictor(img)\n",
    "    v = Visualizer(img[:, :, ::-1], metadata=nuts_metadata , scale=0.5, instance_mode= ColorMode.IMAGE_BW)\n",
    "    try: out = v.draw_box(outputs[\"instances\"].pred_boxes.tensor.tolist()[0])\n",
    "    except: out = v.draw_circle((0,0), radius = 0, color = \"black\")\n",
    "    try: out = v.draw_circle((outputs[\"instances\"].pred_keypoints.tolist())[0][0][:2:], color = \"red\", radius = 3)\n",
    "    except: 1\n",
    "    try: out = v.draw_circle((outputs[\"instances\"].pred_keypoints.tolist())[0][1][:2:], color = \"black\", radius = 2)\n",
    "    except: 1\n",
    "    try: out = v.draw_circle((outputs[\"instances\"].pred_keypoints.tolist())[0][2][:2:], color = \"green\", radius = 2)\n",
    "    except: 1\n",
    "    try: out = v.draw_soft_mask(np.asarray(outputs[\"instances\"].to(\"cpu\").pred_masks)[0,:,:], \"blue\",alpha = 0.3)\n",
    "    except: 1\n",
    "    #out = v.draw_dataset_dict(d)\n",
    "    plt.title(os.path.basename(d[\"file_name\"]))\n",
    "    plt.imshow(out.get_image())\n",
    "    fp = os.path.join(\"C:/R_projects/deep_learning_playground/detectron2/custom_data2/vid_pred2\", os.path.basename(d[\"file_name\"]))\n",
    "    cv2.imwrite(fp, cv2.cvtColor(out.get_image()[:,:,0:3], cv2.COLOR_BGR2RGB))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb39f57c-bd53-41fe-985d-9cb296897a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9,80)) \n",
    "\n",
    "for i in range(len(dataset_dicts)):\n",
    "    fi = dataset_dicts[i][\"file_name\"]\n",
    "    img = cv2.imread(fi)\n",
    "    outputs = predictor(img)\n",
    "    v = Visualizer(img[:, :, ::-1], metadata=nuts_metadata , scale= 0.3, instance_mode= ColorMode.IMAGE_BW)\n",
    "    try: out = v.draw_circle((outputs[\"instances\"].pred_keypoints.tolist())[0][0][:2:], \"red\", radius = 5)\n",
    "    except: \n",
    "        print(\"Head not detected\")  \n",
    "    try: out =  v.draw_box(outputs[\"instances\"].to(\"cpu\").pred_boxes.tensor.tolist()[0])\n",
    "    except: \n",
    "        print(\"Box not detected\") \n",
    "        out =  v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    try: out = v.draw_circle((outputs[\"instances\"].pred_keypoints.tolist())[0][1][:2:], \"black\")\n",
    "    except: print(\"Middle not detected\") \n",
    "    try: out = v.draw_circle((outputs[\"instances\"].pred_keypoints.tolist())[0][2][:2:], \"green\")\n",
    "    except: print(\"Tail not detected\") \n",
    "    try: out = v.draw_soft_mask(np.asarray(outputs[\"instances\"].to(\"cpu\").pred_masks)[0,:,:], \"blue\",alpha = 0.3)\n",
    "    except: print(\"Mask not detected\") \n",
    "    #out = visualizer.draw_dataset_dict(d)\n",
    "    plt.title(os.path.basename(fi))\n",
    "    fig.add_subplot(21, 2, i+1) \n",
    "    plt.imshow(out.get_image(), interpolation='nearest')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570319b6-1d5a-48d7-ae87-5cd860f7eda9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48eb7c3-68a9-495c-acef-dbd4b72d397d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data.datasets.coco import convert_to_coco_json\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "\n",
    "\n",
    "#MetadataCatalog.get('test').set(thing_classes=[\"first\"])\n",
    "\n",
    "#MetadataCatalog.get('cat_data_test')\n",
    "outputs\n",
    "convert_to_coco_dict(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c360b16-6bd6-43f9-83b2-52dc15a30cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81d490f-be57-4cfe-8fc3-9d68e24d07de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf12930-2c0f-4e6d-8853-4e4f042997a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def write_csv(path, df):\n",
    "    keys = dataset[0].keys()\n",
    "    with open(path, \"w\", newline = \"\") as output_file: \n",
    "        dict_writer = csv.DictWriter(output_file, keys)\n",
    "        dict_writer.writeheader()\n",
    "        dict_writer.writerows(df)\n",
    "\n",
    "def img_inference(predictor, rep_ID, root_path):\n",
    "    dataset = []\n",
    "    f = glob.glob(os.path.join(root_path, rep_ID,\"*[!_diff].jpg\"))\n",
    "    tot = len(f)\n",
    "    for i in range(tot):\n",
    "        print(f\"{i+1} of {tot}\", end = \"\\r\")\n",
    "        fi = f[i]\n",
    "        inst = predictor(cv2.imread(fi))[\"instances\"].to(\"cpu\")\n",
    "        data = {}\n",
    "        data[\"file_name\"] = fi\n",
    "        data[\"image_size\"] = list(inst.image_size)\n",
    "        try: data[\"thing_class\"] = MetadataCatalog.get('cat_data_test').get(\"thing_classes\")[inst.pred_classes[0]]\n",
    "        except: data[\"thing_class\"] = \"NA\"\n",
    "        try: data[\"keypoints\"] = np.array(inst.pred_keypoints.tolist()[0]).ravel().tolist()\n",
    "        except: data[\"keypoints\"] = \"NA\"\n",
    "        try: data[\"bbox\"] = inst.pred_boxes.tensor.tolist()[0]\n",
    "        except: data[\"bbox\"] = \"NA\"\n",
    "        try:\n",
    "            cont, _ = cv2.findContours(inst.pred_masks.numpy()[0,:,:].astype('uint8'),cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "            data[\"polygon\"] = cont[0].ravel().tolist()\n",
    "        except: \n",
    "            data[\"polygon\"] = \"NA\"\n",
    "        dataset.append(data)\n",
    "    return(dataset)\n",
    "\n",
    "def write_img_inference(predictor, write_path, rep_ID, read_path):\n",
    "    df = img_inference(predictor, rep_ID, read_path)\n",
    "    write_csv(os.path.join(write_path, rep_ID + \"_inference.csv\"), df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b970bb-9f6a-4669-9727-3efd0752b6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_img_inference(\n",
    "    predictor, \n",
    "    write_path = \"C:/R_projects/deep_learning_playground\",\n",
    "    rep_ID = \"rep50\",\n",
    "    read_path = \"C:/R_projects/spat_1f_noise/processed_feed\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a186cb6-db88-4a48-8013-a75c5554ed6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "[os.path.basename(x) \n",
    " for x in \n",
    " glob.glob(\"C:/R_projects/spat_1f_noise/processed_feed/rep[!week][!trial]*\", recursive=False)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31329a18-6e20-4116-ae18-668a5d734f63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9366471a-aaa0-4fb6-bcc0-f2084bffb7ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d252e345-aac3-4aa0-89d7-67ec603cfee8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89187d0-d344-4d34-8f29-afb2c6546111",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9a4b12-7948-480b-a757-61b04844d1bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dcbdf8-0864-4b78-8b7a-35c38bf72d98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6737004f-f0f5-4a64-bdcc-6fce0dac4932",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon\n",
    "\n",
    "csv_df = pd.DataFrame()\n",
    "    for prediction in glob.glob(os.getcwd() + r\"\\dataset\\predictions\\*pkl\"):\n",
    "        fileName_absolute = os.path.basename(prediction)                 ## get the file name \n",
    "        print(\"The pkl_file name: \", fileName_absolute)\n",
    "        # Read the pkl file\n",
    "        pickleFile = open(prediction,\"rb\")\n",
    "        pickel_Info = pickle.load(pickleFile)\n",
    "        \n",
    "        # Get the 'pred_boxes' values in the pkl file:\n",
    "        boxes = (\n",
    "            pickel_Info[\"prediction\"][\"instances\"]\n",
    "            .get_fields()[\"pred_boxes\"]\n",
    "            .tensor.cpu()\n",
    "            .numpy()\n",
    "        )\n",
    "    \n",
    "        # Get the 'pred_mask' values in the pkl file:\n",
    "        masks = (\n",
    "            pickel_Info[\"prediction\"][\"instances\"]\n",
    "            .get_fields()[\"pred_masks\"]\n",
    "            .cpu()\n",
    "            .numpy()\n",
    "            .astype('uint8')\n",
    "        )\n",
    "    \n",
    "        # Extract the 'contour' of each 'pred_box' by converting pred_box boolean to a 8-bit numpy array:\n",
    "        # Refer to this post to get and visualise the contours: https://stackoverflow.com/questions/73217530/extract-the-masks-values-from-detectron2-object-detection-segmentation-and-then\n",
    "        contours = []\n",
    "        for pred_mask in pickel_Info[\"prediction\"]['instances'].pred_masks:\n",
    "            mask = pred_mask.cpu().numpy().astype('uint8')\n",
    "            contour, _ = cv2.findContours(mask, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "            contours.append(contour[0]) # contour is a tuple (OpenCV 4.5.2), so take the first element which is the array of contour points\n",
    "        \n",
    "    \n",
    "        # save boxes and masks-polygons\n",
    "        dataset = []\n",
    "        counter_box = 0\n",
    "        for i, box in enumerate(boxes):\n",
    "            data = {}\n",
    "            data[\"file_name\"] = pickel_Info['file_name']\n",
    "            data[\"file_location\"] = pickel_Info[\"file_location\"]\n",
    "            data[\"image_height\"] = pickel_Info[\"prediction\"][\"instances\"].image_size[0]\n",
    "            data[\"image_width\"] = pickel_Info[\"prediction\"][\"instances\"].image_size[1]\n",
    "            data[\"bounding_box\"] = box\n",
    "            data[\"mask\"] = masks[i]\n",
    "            data[\"contours\"] = contours[i]\n",
    "            data[\"polygon\"] = Polygon(np.squeeze(contours[i]))\n",
    "            data[\"id\"] = \"id_{counter_box}\"\n",
    "            counter_box = counter_box + 1\n",
    "    \n",
    "            dataset.append(data)\n",
    "    \n",
    "        df = pd.DataFrame(dataset)\n",
    "    \n",
    "        \n",
    "        # keep specific columns for the csv file\n",
    "        df = df[\n",
    "            [\n",
    "                \"file_name\",\n",
    "                \"id\",\n",
    "                \"bounding_box\",\n",
    "                \"polygon\",\n",
    "            ]\n",
    "        ]\n",
    "    \n",
    "        csv_df = csv_df.append(df)\n",
    "    print ('## csv_df: ', csv_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
