{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee586206-75a5-4560-b695-bd9780f3f9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Installation info\n",
    "# conda create -n detectron_env python=3.8\n",
    "# conda activate detectron_env\n",
    "# conda install cython\n",
    "# conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia\n",
    "# git clone https://github.com/facebookresearch/detectron2.git\n",
    "# cd detectron2\n",
    "# conda install -e .\n",
    "# conda install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a4a659-99fa-4ae5-a0be-31f206071eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Virtual environment and notebook init\n",
    "# Call conda activate detectron_env\n",
    "# cd C:\\R_projects\\deep_learning_playground\n",
    "# Call jupyter lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7220c27-d638-46b8-a07a-e31ff594af2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check working directory\n",
    "# pwd\n",
    "### Check if entered correct environment\n",
    "# conda info --envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614d3637-2f19-410a-ad9e-d760b70e4d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, detectron2\n",
    "!nvcc --version\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "print(\"detectron2:\", detectron2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78437cf5-f4e6-4e4a-905b-b793424ad3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor,DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.utils.visualizer import ColorMode,GenericMask,Visualizer\n",
    "from detectron2.structures.keypoints import heatmaps_to_keypoints\n",
    "from detectron2.structures.keypoints_hack import heatmaps_to_keypoints2, heatmaps_to_keypoints_iterative, heatmaps_modify_iterative\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "import random\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.evaluation import (\n",
    "    CityscapesInstanceEvaluator,\n",
    "    CityscapesSemSegEvaluator,\n",
    "    COCOEvaluator,\n",
    "    COCOPanopticEvaluator,\n",
    "    LVISEvaluator,\n",
    "    PascalVOCDetectionEvaluator,\n",
    "    SemSegEvaluator,\n",
    "    DatasetEvaluator,\n",
    "    inference_on_dataset,\n",
    "    print_csv_format,\n",
    "    verify_results,\n",
    ")\n",
    "import cv2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea952b8d-9d32-4c39-91e9-ffcfe226dd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd C:\\R_projects\\deep_learning_playground\\detectron2\\custom_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e90549-fc6e-4899-9030-c862cf67f80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and test data\n",
    "#!coco-split --has_annotations --valid_ratio 0 --test_ratio 0.1 --annotations_file ./caterpillar_12_09_2023_with_keypoints.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39ae945-4c3e-4101-902b-608064303c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine.hooks import HookBase\n",
    "from detectron2.evaluation import inference_context\n",
    "from detectron2.utils.logger import log_every_n_seconds\n",
    "from detectron2.data import DatasetMapper, build_detection_test_loader\n",
    "import detectron2.utils.comm as comm\n",
    "import torch\n",
    "import time\n",
    "import datetime\n",
    "import logging\n",
    "\n",
    "class LossEvalHook(HookBase):\n",
    "    def __init__(self, eval_period, model, data_loader):\n",
    "        self._model = model\n",
    "        self._period = eval_period\n",
    "        self._data_loader = data_loader\n",
    "    \n",
    "    def _do_loss_eval(self):\n",
    "        # Copying inference_on_dataset from evaluator.py\n",
    "        total = len(self._data_loader)\n",
    "        num_warmup = min(5, total - 1)\n",
    "            \n",
    "        start_time = time.perf_counter()\n",
    "        total_compute_time = 0\n",
    "        losses = []\n",
    "        for idx, inputs in enumerate(self._data_loader):            \n",
    "            if idx == num_warmup:\n",
    "                start_time = time.perf_counter()\n",
    "                total_compute_time = 0\n",
    "            start_compute_time = time.perf_counter()\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.synchronize()\n",
    "            total_compute_time += time.perf_counter() - start_compute_time\n",
    "            iters_after_start = idx + 1 - num_warmup * int(idx >= num_warmup)\n",
    "            seconds_per_img = total_compute_time / iters_after_start\n",
    "            if idx >= num_warmup * 2 or seconds_per_img > 5:\n",
    "                total_seconds_per_img = (time.perf_counter() - start_time) / iters_after_start\n",
    "                eta = datetime.timedelta(seconds=int(total_seconds_per_img * (total - idx - 1)))\n",
    "                log_every_n_seconds(\n",
    "                    logging.INFO,\n",
    "                    \"Loss on Validation  done {}/{}. {:.4f} s / img. ETA={}\".format(\n",
    "                        idx + 1, total, seconds_per_img, str(eta)\n",
    "                    ),\n",
    "                    n=5,\n",
    "                )\n",
    "            loss_batch = self._get_loss(inputs)\n",
    "            losses.append(loss_batch)\n",
    "        mean_loss = np.mean(losses)\n",
    "        self.trainer.storage.put_scalar('validation_loss', mean_loss)\n",
    "        comm.synchronize()\n",
    "\n",
    "        return losses\n",
    "            \n",
    "    def _get_loss(self, data):\n",
    "        # How loss is calculated on train_loop \n",
    "        metrics_dict = self._model(data)\n",
    "        metrics_dict = {\n",
    "            k: v.detach().cpu().item() if isinstance(v, torch.Tensor) else float(v)\n",
    "            for k, v in metrics_dict.items()\n",
    "        }\n",
    "        total_losses_reduced = sum(loss for loss in metrics_dict.values())\n",
    "        return total_losses_reduced\n",
    "        \n",
    "        \n",
    "    def after_step(self):\n",
    "        next_iter = self.trainer.iter + 1\n",
    "        is_final = next_iter == self.trainer.max_iter\n",
    "        if is_final or (self._period > 0 and next_iter % self._period == 0):\n",
    "            self._do_loss_eval()\n",
    "        self.trainer.storage.put_scalars(timetest=12)\n",
    "\n",
    "from detectron2.data import DatasetMapper, build_detection_test_loader\n",
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "class CustomTrainer(DefaultTrainer):\n",
    "    \"\"\"\n",
    "    Custom Trainer deriving from the \"DefaultTrainer\"\n",
    "\n",
    "    Overloads build_hooks to add a hook to calculate loss on the test set during training.\n",
    "    \"\"\"\n",
    "\n",
    "    def build_hooks(self):\n",
    "        hooks = super().build_hooks()\n",
    "        hooks.insert(-1, LossEvalHook(\n",
    "            200, # Frequency of calculation - every 100 iterations here\n",
    "            self.model,\n",
    "            build_detection_test_loader(\n",
    "                self.cfg,\n",
    "                self.cfg.DATASETS.TEST[0],\n",
    "                DatasetMapper(self.cfg, True)\n",
    "            )\n",
    "        ))\n",
    "\n",
    "        return hooks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b908c2ab-2c50-4621-84fa-205c29562d83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "register_coco_instances(\"cat_data_train\", {}, \".\\coco_train.json\", \".\\datasets\\caterpillar\")\n",
    "register_coco_instances(\"cat_data_test\", {}, \".\\coco_test.json\", \".\\datasets\\caterpillar\")\n",
    "#register_coco_instances(\"cat_data_val\", {}, \".\\valid.json\", \".\\datasets\\caterpillar\")\n",
    "MetadataCatalog.get(\"cat_data_train\").set(thing_classes=[\"cat\"])\n",
    "MetadataCatalog.get(\"cat_data_train\").set(thing_colors=(0,0,255))\n",
    "MetadataCatalog.get(\"cat_data_test\").set(thing_classes=[\"cat\"])\n",
    "MetadataCatalog.get(\"cat_data_test\").set(thing_colors=(0,0,255))\n",
    "MetadataCatalog.get(\"cat_data_train\").set(keypoint_names=[\"head\",\"middle\",\"tail\"])\n",
    "MetadataCatalog.get(\"cat_data_train\").set(keypoint_flip_map=[])\n",
    "MetadataCatalog.get(\"cat_data_test\").set(keypoint_names=[\"head\",\"middle\",\"tail\"])\n",
    "MetadataCatalog.get(\"cat_data_test\").set(keypoint_flip_map=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6a2f5b-0a9e-4407-94d5-d92bc6dd5519",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"cat_data_train\",)\n",
    "cfg.DATASETS.TEST = (\"cat_data_test\", )\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.TEST.EVAL_PERIOD = 200\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2  # This is the real \"batch size\" commonly known to deep learning people\n",
    "cfg.SOLVER.BASE_LR = 0.00015  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 3000    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
    "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # The \"RoIHead batch size\". 128 is faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1 \n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.9\n",
    "cfg.TEST.DETECTIONS_PER_IMAGE = 1\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = 2000\n",
    "cfg.MODEL.ROI_KEYPOINT_HEAD.NUM_KEYPOINTS = 3\n",
    "cfg.TEST.KEYPOINT_OKS_SIGMAS = [0.1, 0.3, 0.1]\n",
    "cfg.INPUT.RANDOM_FLIP = \"horizontal\"\n",
    "cfg.MODEL.MASK_ON = True\n",
    "cfg.MODEL.KEYPOINT_ON = True\n",
    "cfg.MODEL.ROI_KEYPOINT_HEAD.LOSS_WEIGHT = 5\n",
    "cfg.MODEL.ROI_KEYPOINT_HEAD.NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS = False\n",
    "#cfg.MODEL.ROI_KEYPOINT_HEAD.ITERATIVE = True\n",
    "cfg.OUTPUT_DIR = \"./output4\"\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f49cee-eb96-4a0a-a4fd-549523976d19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5682be-ce19-4308-90de-fa211a21e937",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecbdc5b-59a6-4906-bd61-45cd0e9d6f61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#trainer = DefaultTrainer(cfg)\n",
    "trainer = CustomTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845ee350-0d0a-4bf5-975d-39aed5e9bece",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "#%reload_ext tensorboard\n",
    "%tensorboard --logdir \"./output4\"\n",
    "# !del /S C:\\Users\\vsbpa\\AppData\\Local\\Temp\\.tensorboard-info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29502328-f162-4531-b70d-f246bad5e7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference should use the config with parameters that are used in training\n",
    "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_0001999.pth\")  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.9  # set a custom testing threshold\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8020887a-df4d-4687-9bf8-b6e6319a94b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "# f = glob.glob(\"C:\\R_projects\\deep_learning_playground\\detectron2\\custom_data\\coco_dataset\\*.jpg\")\n",
    "f = glob.glob(\"C:/R_projects/spat_1f_noise/processed_feed/rep50/*.jpg\")\n",
    "# f = [\"C:/R_projects/spat_1f_noise/processed_feed/repweek2test2/processed_repweek2test2__cam28_s36764_rank103.jpg\"]\n",
    "fi = random.choice(f)\n",
    "#fi = f[0]\n",
    "im = cv2.imread(fi)\n",
    "outputs = predictor(im)  # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
    "v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata=MetadataCatalog.get(\"cat_data_train\"), \n",
    "                   scale=1, \n",
    "               instance_mode=ColorMode.IMAGE_BW\n",
    ")\n",
    "#out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "try: out = v.draw_circle((outputs[\"instances\"].pred_keypoints.tolist())[0][0][:2:], \"red\", radius = 5)\n",
    "except: print(\"Head not detected\") \n",
    "try: out = v.draw_circle((outputs[\"instances\"].pred_keypoints.tolist())[0][1][:2:], \"black\")\n",
    "except: print(\"Middle not detected\") \n",
    "try: out = v.draw_circle((outputs[\"instances\"].pred_keypoints.tolist())[0][2][:2:], \"green\")\n",
    "except: print(\"Tail not detected\") \n",
    "try: out = v.draw_soft_mask(np.asarray(outputs[\"instances\"].to(\"cpu\").pred_masks)[0,:,:], \"blue\",alpha = 0.3)\n",
    "except: print(\"Mask not detected\") \n",
    "\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.imshow(out.get_image(), interpolation='nearest')\n",
    "plt.title(fi)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e2b72e-66f6-405f-bb37-62354579ac52",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = glob.glob(\"C:/R_projects/spat_1f_noise/processed_feed/rep50/*.jpg\")\n",
    "tot = len(f)\n",
    "for i in range(tot):\n",
    "    fi = f[i]\n",
    "    im = cv2.imread(fi)\n",
    "    outputs = predictor(im) \n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata=MetadataCatalog.get(\"cat_data_train\"), \n",
    "                   scale=0.5, \n",
    "                   instance_mode=ColorMode.IMAGE_BW\n",
    "    )\n",
    "    #out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    try: out = v.draw_box(outputs[\"instances\"].pred_boxes.tensor.tolist()[0])\n",
    "    except: out = v.draw_circle((0,0), radius = 0, color = \"black\")\n",
    "    try: out = v.draw_circle((outputs[\"instances\"].pred_keypoints.tolist())[0][0][:2:], color = \"red\", radius = 3)\n",
    "    except: 1\n",
    "    try: out = v.draw_circle((outputs[\"instances\"].pred_keypoints.tolist())[0][1][:2:], color = \"black\", radius = 2)\n",
    "    except: 1\n",
    "    try: out = v.draw_circle((outputs[\"instances\"].pred_keypoints.tolist())[0][2][:2:], color = \"green\", radius = 2)\n",
    "    except: 1\n",
    "    try: out = v.draw_soft_mask(np.asarray(outputs[\"instances\"].to(\"cpu\").pred_masks)[0,:,:], \"blue\",alpha = 0.3)\n",
    "    except: 1\n",
    "    fp = os.path.join(\"C:/R_projects/deep_learning_playground/detectron2/custom_data2/vid_pred\", os.path.basename(fi))\n",
    "    cv2.imwrite(fp, cv2.cvtColor(out.get_image(), cv2.COLOR_BGR2RGB))\n",
    "    print(f\"{i+1} of {tot}\", end = \"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c3a60c-010e-4db4-8225-6156067865e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7978a31f-4d0a-4e6a-b8f7-c193431e6d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = np.asarray(outputs['instances'].pred_keypoint_heatmaps.to(\"cpu\"))[0,1,:,:]\n",
    "roi_box = outputs['instances'].pred_boxes.tensor\n",
    "#plt.imshow(a, cmap='hot', interpolation='nearest')\n",
    "from detectron2.structures.keypoints import Keypoints, heatmaps_to_keypoints\n",
    "\n",
    "heat_map_og = outputs['instances'].pred_keypoint_heatmaps\n",
    "\n",
    "print(\n",
    "    heatmaps_to_keypoints(heat_map_og, roi_box)\n",
    ")\n",
    "\n",
    "penalty = -30\n",
    "nscale = 3\n",
    "w = heat_map_og.shape[2]\n",
    "h = heat_map_og.shape[3]\n",
    "nkps = heat_map_og.shape[1]\n",
    "grid = torch.tensor([(x, y) for x in range(w) \n",
    "              for y in range(h)], \n",
    "              device = heat_map_og.device)\n",
    "r2 = (max([h,w])/nscale)**2\n",
    "\n",
    "first_kp_pred = heatmaps_to_keypoints2(heat_map_og, roi_box)\n",
    "first_best_kp_pos = torch.argmax(first_kp_pred[0][:,2])\n",
    "first_best_kp = first_kp_pred[0,first_best_kp_pos][0:2]\n",
    "\n",
    "region_mask = grid[\n",
    "    ((grid[:,0] - int(first_best_kp[0]))**2 + \n",
    "    (grid[:,1] - int(first_best_kp[1]))**2) < \n",
    "    r2,\n",
    "    :]\n",
    "\n",
    "flat_inds = [int(region_mask[i, 0] + region_mask[i, 1] * w) for i in range(region_mask.shape[0])]\n",
    "\n",
    "for i in range(nkps):\n",
    "    if(i == first_best_kp_pos):\n",
    "        continue\n",
    "    heat_map_og.reshape((3,-1,))[i,[flat_inds]] = torch.tensor(\n",
    "        penalty,\n",
    "        device = heat_map_og.device,\n",
    "        dtype = heat_map_og.dtype\n",
    "    )\n",
    "\n",
    "second_kp_pred = heatmaps_to_keypoints2(heat_map_og, roi_box)\n",
    "second_best_kp_pos = second_kp_pred[0][:,2].topk(2).indices[1]\n",
    "second_best_kp = second_kp_pred[0,second_best_kp_pos][0:2]\n",
    "\n",
    "region_mask = grid[\n",
    "    ((grid[:,0] - int(second_best_kp[0]))**2 + \n",
    "    (grid[:,1] - int(second_best_kp[1]))**2) < \n",
    "    r2,\n",
    "    :]\n",
    "\n",
    "flat_inds = [int(region_mask[i, 0] + region_mask[i, 1] * w) for i in range(region_mask.shape[0])]\n",
    "\n",
    "for i in range(nkps):\n",
    "    if(i == first_best_kp_pos or i == second_best_kp_pos):\n",
    "        continue\n",
    "    heat_map_og.reshape((3,-1,))[i,[flat_inds]] = torch.tensor(\n",
    "        penalty,\n",
    "        device = heat_map_og.device,\n",
    "        dtype = heat_map_og.dtype\n",
    "    )\n",
    "\n",
    "print(\n",
    "    heatmaps_to_keypoints(heat_map_og, roi_box)\n",
    ")\n",
    "fig = plt.figure(figsize=(20,20)) \n",
    "fig.add_subplot(2, 2, 1)\n",
    "\n",
    "plt.imshow(np.asarray(heat_map_og.to(\"cpu\")[0,0,:,:]), cmap='hot', interpolation='nearest')\n",
    "fig.add_subplot(2, 2, 2)\n",
    "plt.imshow(np.asarray(heat_map_og.to(\"cpu\")[0,1,:,:]), cmap='hot', interpolation='nearest')\n",
    "fig.add_subplot(2, 2, 3)\n",
    "plt.imshow(np.asarray(heat_map_og.to(\"cpu\")[0,2,:,:]), cmap='hot', interpolation='nearest')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bc75f0-ac74-46db-ac8f-ce02762e979d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8111e523-4ede-4018-ab34-ab9119314e24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef49502a-20bd-4980-be6c-43f93111796a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c9e763-6edc-4a7b-b6a1-f05216bddedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread(fi)\n",
    "outputs = predictor(im) \n",
    "v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata=MetadataCatalog.get(\"cat_data_train\"), \n",
    "                   scale=1, \n",
    "               instance_mode=ColorMode.IMAGE_BW\n",
    ")\n",
    "\n",
    "final_kpts = heatmaps_to_keypoints_iterative(outputs['instances'].pred_keypoint_heatmaps, roi_box).to(\"cpu\")\n",
    "\n",
    "try: out = v.draw_circle((final_kpts.tolist())[0][0][:2:], \"red\", radius = 5)\n",
    "except: print(\"Head not detected\") \n",
    "try: out = v.draw_circle((final_kpts.tolist())[0][1][:2:], \"black\")\n",
    "except: print(\"Middle not detected\") \n",
    "try: out = v.draw_circle((final_kpts.tolist())[0][2][:2:], \"green\")\n",
    "except: print(\"Tail not detected\")\n",
    "\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.imshow(out.get_image(), interpolation='nearest')\n",
    "plt.title(fi)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5e73d3-6056-499e-94ba-942d1cf74dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.structures.keypoints_hack import heatmaps_to_keypoints_iterative\n",
    "\n",
    "print(heatmaps_to_keypoints_iterative(outputs['instances'].pred_keypoint_heatmaps, roi_box))\n",
    "print(heatmaps_to_keypoints(outputs['instances'].pred_keypoint_heatmaps, roi_box))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50399fbf-5f3a-450f-8863-6370ea9ca80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmaps_modify_iterative(outputs[\"instances\"].pred_keypoint_heatmaps, None, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671b5042-f674-4896-b0f2-f64a7d96b7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,20)) \n",
    "fig.add_subplot(2, 2, 1)\n",
    "plt.imshow(np.asarray(outputs[\"instances\"].pred_keypoint_heatmaps.to(\"cpu\")[0,0,:,:]), cmap='hot', interpolation='nearest')\n",
    "fig.add_subplot(2, 2, 2)\n",
    "plt.imshow(np.asarray(outputs[\"instances\"].pred_keypoint_heatmaps.to(\"cpu\")[0,1,:,:]), cmap='hot', interpolation='nearest')\n",
    "fig.add_subplot(2, 2, 3)\n",
    "plt.imshow(np.asarray(outputs[\"instances\"].pred_keypoint_heatmaps.to(\"cpu\")[0,2,:,:]), cmap='hot', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abce68df-cd61-436e-a84a-f7aa27bbd9d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd35783-4181-4250-9117-00b6db651b79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74837f88-ca3f-43f8-9516-033c20a9044f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8071387-91ed-4092-b402-bd50fc96a030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1cf317-7e58-4bb4-876e-31d6b6548240",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492413ca-d9c3-4014-9d5a-2653b7e450bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cfg.MODEL.WEIGHTS = os.path.join(\"./output4/\", \"model_0005999.pth\")  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.9  # set a custom testing threshold\n",
    "predictor = DefaultPredictor(cfg)\n",
    "evaluator = COCOEvaluator(\"cat_data_test\",tasks=[\"bbox\",\"segm\",\"keypoints\"], distributed=False, max_dets_per_image=1, \n",
    "                          use_fast_impl=False, allow_cached_coco= False, output_dir=\"./output/\", kpt_oks_sigmas = [0.1,0.5,0.1])\n",
    "val_loader = build_detection_test_loader(cfg, \"cat_data_test\")\n",
    "detectron2.evaluation.inference_on_dataset(predictor.model, val_loader, evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9e8659-e64b-4738-a473-b495a71ce1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuts_metadata = MetadataCatalog.get('cat_data_test')\n",
    "dataset_dicts = DatasetCatalog.get(\"cat_data_test\")\n",
    "fig = plt.figure(figsize=(10,30)) \n",
    "\n",
    "i = 0\n",
    "for d in dataset_dicts[0:10]:\n",
    "    i += 1\n",
    "    fig.add_subplot(10, 2, i) \n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    outputs = predictor(img)\n",
    "    v = Visualizer(img[:, :, ::-1], metadata=nuts_metadata , scale=0.5)\n",
    "    try: out = v.draw_circle((outputs[\"instances\"].pred_keypoints.tolist())[0][0][:2:], \"red\", radius = 5)\n",
    "    except: print(\"Head not detected\\r\") \n",
    "    try: out = v.draw_circle((outputs[\"instances\"].pred_keypoints.tolist())[0][1][:2:], \"blue\")\n",
    "    except: print(\"Middle not detected\\r\") \n",
    "    try: out = v.draw_circle((outputs[\"instances\"].pred_keypoints.tolist())[0][2][:2:], \"green\")\n",
    "    except: print(\"Tail not detected\\r\") \n",
    "    #out = v.draw_dataset_dict(d)\n",
    "    plt.imshow(out.get_image()[:, :, ::-1])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb39f57c-bd53-41fe-985d-9cb296897a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,100)) \n",
    "\n",
    "i = 0\n",
    "for d in dataset_dicts:\n",
    "    i += 1\n",
    "    fig.add_subplot(10, 2, i) \n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    outputs = predictor(img)\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=nuts_metadata , scale= 0.3, instance_mode= ColorMode.IMAGE_BW)\n",
    "    out = visualizer.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    out = visualizer.draw_dataset_dict(d)\n",
    "    plt.title(d[\"file_name\"])\n",
    "    plt.imshow(out.get_image()[:, :, ::-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570319b6-1d5a-48d7-ae87-5cd860f7eda9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b6c6e0-fb23-4666-8be0-6de1fa86cc70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48eb7c3-68a9-495c-acef-dbd4b72d397d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
